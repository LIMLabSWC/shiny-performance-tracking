---

title: "Architecture and Data Flow Overview"
output: html\_document
----------------------

# Project Overview

This project implements a complete pipeline to **import**, **process**, **analyze**, and **visualize** rodent training data collected from behavioral experiments using BControl and Bpod systems. A Shiny web app provides an interactive frontend for exploring animal performance.

# Repository Structure

```
shiny-performance-tracking/
├── analysis.R                 # Exploratory data analysis
├── dependencies.R             # Dependency management (if any)
├── exploring_data.R          # Ad-hoc data exploration
├── ExtractSaveData.R         # Main data ingestion + processing script
├── README.md
├── shiny_app/
│   ├── app.R                 # Main Shiny app
│   ├── TRAINING.csv          # Aggregated preprocessed data
│   ├── full_TRAINING.csv     # (Possibly extended version)
│   ├── functions/            # Plot modules
│   │   ├── ChoiceDirectionPlot.R
│   │   ├── CompletedTrialsPlot.R
│   │   ├── CorrectRatioPlot.R
│   │   ├── StageTrackingPlot.R
│   │   ├── load_data.R       # Loads and cleans TRAINING.csv
│   │   └── plot_theme_settings.R
│   └── rsconnect/            # ShinyApps.io deployment config
├── utility_functions/
│   ├── ConvertToRDS.R        # .mat to .rds converter
│   ├── ReadBcontrolData.R    # Extracts data from BControl
│   ├── ReadBonsaiData.R      # (Not yet reviewed)
│   ├── ReadBpodData.R        # Extracts data from Bpod
│   ├── ReadData.R            # Dispatches RDS reading
│   ├── ReadTrialData.R       # (Not yet reviewed)
│   └── TRAININGtoCSV.R       # Appends data to csv
└── docs/                     # Documentation files (this folder)
```

# Data Processing Pipeline

## 1. Raw Data Ingestion

* `.mat` files are stored in a directory (`path_to_mat_files`).
* `ExtractSaveData.R`:

  * Filters out irrelevant files.
  * Converts new `.mat` files into `.rds` format using `ConvertToRDS.R`.
  * Calls `ReadData.R` to extract relevant training metrics.
  * Writes the parsed data to `shiny_app/TRAINING.csv` via `TRAININGtoCSV.R`.

## 2. Data Parsing Logic

* `ReadData.R` acts as a dispatcher:

  * For files with a `saved` field: uses `ReadBcontrolData.R`
  * For files with `SessionData`: uses `ReadBpodData.R`
  * Optional `trialData=TRUE` logic for fine-grained trial parsing

Each reader function constructs a standardized list containing metadata, trial counts, performance metrics, timestamps, etc.

## 3. Data Cleaning and Transformation

* `load_data.R` (used by the Shiny app):

  * Converts date and time columns
  * Re-labels stages into meaningful names
  * Extracts key performance variables (e.g., `No_pokes` by choice direction)
  * Pivots data into long format suitable for ggplot

## 4. Visualization

Modular plot functions are located in `shiny_app/functions/` and include:

| File                    | Description                                |
| ----------------------- | ------------------------------------------ |
| `ChoiceDirectionPlot.R` | Boxplot of left/right poke counts          |
| `CompletedTrialsPlot.R` | Daily count of completed trials            |
| `CorrectRatioPlot.R`    | Ratio of correct to completed trials       |
| `StageTrackingPlot.R`   | Visual progression through training stages |

All use `ggplot2`, `dplyr`, and custom theming from `plot_theme_settings.R`.

## 5. Shiny Application

* `app.R` integrates the visual modules and provides UI for filtering data by:

  * Animal ID
  * Experimenter
  * Protocol
  * Stage
  * Date range

The app is deployed via `shinyapps.io` using config files in `rsconnect/`.

# Suggestions for Extension

* Add support for Bonsai data (see `ReadBonsaiData.R`).
* Export trial-level data (`TrialByTrial.csv`) for detailed modeling.
* Use `roxygen2` for all function docstrings.
* Add a `data_dictionary.md` describing the fields in `TRAINING.csv`.

# Authors and Contributors

* Initial design and implementation: Viktor Plattner
* Repository maintained by Akrami Lab

---

> This file is part of the `docs/` folder and aims to serve as a technical orientation for new contributors.
